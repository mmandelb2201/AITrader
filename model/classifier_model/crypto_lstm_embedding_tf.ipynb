{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "868f1e69",
   "metadata": {},
   "source": [
    "\n",
    "# Crypto LSTM with Asset Embeddings (TensorFlow)\n",
    "\n",
    "This notebook builds a full pipeline to train a stacked LSTM with **asset embeddings** on your wide table of hourly data:\n",
    "- `time`\n",
    "- `<ASSET>_price` and `<ASSET>_volume` for each asset (e.g., `BTC_price`, `BTC_volume`, ...)\n",
    "\n",
    "You can drop your wide DataFrame in as `df_wide` and run end-to-end.\n",
    "\n",
    "> Generated: 2025-09-03T02:56:41Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fcdd61ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Setup & Config ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, concatenate, Embedding, Reshape, BatchNormalization\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.saving import save_model\n",
    "\n",
    "print(\"TF version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69d014aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK_L = 48     # lookback window length (hours)\n",
    "HORIZON_H  = 6      # prediction horizon (hours)\n",
    "BATCH_TRAIN = 256\n",
    "BATCH_EVAL  = 512\n",
    "EPOCHS = 30\n",
    "\n",
    "ASSUME_TZ = None\n",
    "\n",
    "FEATURES = [\"price_pct_change\"]\n",
    "TARGET   = \"target_pct_chage\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f8b17",
   "metadata": {},
   "source": [
    "\n",
    "## Load your data (`df_wide`) & drop empty assets\n",
    "\n",
    "Expected format: wide DataFrame with\n",
    "- `time`\n",
    "- `<ASSET>_price`, `<ASSET>_volume`\n",
    "\n",
    "We will **drop any asset** whose `_price` and `_volume` columns are entirely NaN **before** reshaping.\n",
    "If `df_wide` is not defined, we create a small toy dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e942c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = pd.read_csv(\"crypto_market_dataset.csv\", dtype={\"time\": \"string\"})\n",
    "\n",
    "# Best: ISO8601 parser (handles 'T', fractional seconds, and 'Z')\n",
    "df_wide[\"time\"] = pd.to_datetime(df_wide[\"time\"], format=\"ISO8601\", utc=True)\n",
    "\n",
    "# --- Normalize column names: rename *_close -> *_price ---\n",
    "rename_map = {}\n",
    "for col in df_wide.columns:\n",
    "    if col.endswith(\"_close\"):\n",
    "        asset = col.rsplit(\"_\", 1)[0]   # everything before \"_close\"\n",
    "        rename_map[col] = f\"{asset}_price\"\n",
    "\n",
    "if rename_map:\n",
    "    df_wide = df_wide.rename(columns=rename_map)\n",
    "    print(\"Renamed columns:\", rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a385ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_majority_window(df_wide, min_frac=0.8):\n",
    "    \"\"\"\n",
    "    Given df_wide with columns:\n",
    "        - 'time'\n",
    "        - <ASSET>_price, <ASSET>_volume\n",
    "    Returns the largest contiguous [start, end] where\n",
    "    at least `min_frac` of assets have data at each timestamp.\n",
    "    \"\"\"\n",
    "    df = df_wide.copy()\n",
    "    df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "\n",
    "    # Identify asset prefixes\n",
    "    assets = sorted({c.split(\"_\")[0] for c in df.columns if c.endswith((\"_price\",\"_volume\"))})\n",
    "\n",
    "    # Count how many assets are non-NaN at each timestamp (price only)\n",
    "    price_cols = [f\"{a}_price\" for a in assets if f\"{a}_price\" in df.columns]\n",
    "    df['available'] = df[price_cols].notna().sum(axis=1)\n",
    "\n",
    "    # Fraction of available assets at each time\n",
    "    df['coverage'] = df['available'] / len(price_cols)\n",
    "\n",
    "    # Mask where coverage >= threshold\n",
    "    mask = df['coverage'] >= min_frac\n",
    "\n",
    "    # Find contiguous runs of True\n",
    "    df['block'] = (mask != mask.shift()).cumsum()\n",
    "    runs = (\n",
    "        df.loc[mask]\n",
    "          .groupby('block')\n",
    "          .agg(start=('time','min'), end=('time','max'), length=('time','count'))\n",
    "    )\n",
    "\n",
    "    if runs.empty:\n",
    "        raise RuntimeError(\"No window satisfies coverage threshold.\")\n",
    "\n",
    "    # Pick the longest run\n",
    "    best = runs.loc[runs['length'].idxmax()]\n",
    "    return best['start'], best['end'], runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d402ee49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best window: 2024-03-21 12:00:00+00:00 → 2025-09-03 15:00:00+00:00 (length 12658 rows)\n"
     ]
    }
   ],
   "source": [
    "start, end, runs = find_majority_window(df_wide, min_frac=0.6)\n",
    "print(\"Best window:\", start, \"→\", end, f\"(length {runs['length'].max()} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca7d5383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (92559, 55)\n",
      "Trimmed shape: (12658, 55)\n",
      "Window: 2024-03-21 12:00:00+00:00 → 2025-09-03 15:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "df_cut = df_wide[(df_wide[\"time\"] >= start) & (df_wide[\"time\"] <= end)].copy()\n",
    "\n",
    "print(\"Original shape:\", df_wide.shape)\n",
    "print(\"Trimmed shape:\", df_cut.shape)\n",
    "print(\"Window:\", start, \"→\", end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "277b4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data = df_wide[(df_wide[\"time\"] < start)].copy()\n",
    "eth_data = pd.DataFrame()\n",
    "eth_data[\"time\"] = df_test_data[\"time\"].values\n",
    "eth_data[\"ETH_price\"] = df_test_data[\"ETH_price\"].values\n",
    "eth_data[\"ETH_volume\"] = df_test_data[\"ETH_volume\"].values\n",
    "\n",
    "eth_data.to_csv(\"./paper_wallet_data/eth_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de315736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped sparse assets (name, price%, volume%):\n",
      "  ENA     price=17.03%, volume=17.03%\n",
      "  HYPE    price=13.26%, volume=13.26%\n",
      "  MNT     price=63.79%, volume=63.79%\n",
      "  PEPE    price=55.71%, volume=55.71%\n",
      "  TAO     price=36.63%, volume=36.63%\n",
      "  TON     price=61.28%, volume=61.28%\n",
      "  WLFI    price=0.40%, volume=0.40%\n",
      "Remaining assets: ['AAVE', 'ADA', 'AVAX', 'BCH', 'BTC', 'DOGE', 'DOT', 'ETC', 'ETH', 'HBAR'] ... (total: 20 )\n"
     ]
    }
   ],
   "source": [
    "# --- Drop sparse assets (<90% non-NaN in price or volume) ---\n",
    "threshold = 0.9\n",
    "n_rows = len(df_cut)\n",
    "\n",
    "asset_prefixes = {c.split(\"_\")[0] for c in df_cut.columns if \"_\" in c and c != \"time\"}\n",
    "drop_cols = []\n",
    "dropped_assets = []\n",
    "\n",
    "for a in sorted(asset_prefixes):\n",
    "    p, v = f\"{a}_price\", f\"{a}_volume\"\n",
    "    if p in df_cut.columns and v in df_cut.columns:\n",
    "        frac_price  = df_cut[p].notna().mean()\n",
    "        frac_volume = df_cut[v].notna().mean()\n",
    "        if (frac_price < threshold) or (frac_volume < threshold):\n",
    "            drop_cols += [p, v]\n",
    "            dropped_assets.append((a, frac_price, frac_volume))\n",
    "\n",
    "if drop_cols:\n",
    "    df_cut = df_cut.drop(columns=drop_cols)\n",
    "    print(\"Dropped sparse assets (name, price%, volume%):\")\n",
    "    for a, fp, fv in dropped_assets:\n",
    "        print(f\"  {a:6s}  price={fp:.2%}, volume={fv:.2%}\")\n",
    "\n",
    "remaining_assets = sorted({c.split(\"_\")[0] for c in df_cut.columns if \"_\" in c and c != \"time\"})\n",
    "print(\"Remaining assets:\", remaining_assets[:10], \"... (total:\", len(remaining_assets), \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2519e1",
   "metadata": {},
   "source": [
    "\n",
    "## Reshape wide → long & hourly reindex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26bec79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long shape after reindex: (254958, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:25: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  long = df.stack(\"asset\").reset_index().rename(columns={(\"__meta__\",\"time\"): \"time\"})\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  g = g.set_index(\"time\").asfreq(\"1H\")\n",
      "/var/folders/1f/5lhk7sb97rz53v7gk1vkcjkr0000gn/T/ipykernel_1054/1418215485.py:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  long = long.groupby(\"asset\", group_keys=False).apply(reindex_hourly)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>field</th>\n",
       "      <th>time</th>\n",
       "      <th>asset</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-21 13:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>120.29</td>\n",
       "      <td>119.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-21 14:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.29</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-21 15:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>120.29</td>\n",
       "      <td>1355.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-21 16:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>123.01</td>\n",
       "      <td>4274.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-21 17:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>122.06</td>\n",
       "      <td>7042.400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "field                      time asset   price    volume\n",
       "0     2024-03-21 13:00:00+00:00  AAVE  120.29   119.004\n",
       "1     2024-03-21 14:00:00+00:00   NaN  120.29     0.000\n",
       "2     2024-03-21 15:00:00+00:00  AAVE  120.29  1355.469\n",
       "3     2024-03-21 16:00:00+00:00  AAVE  123.01  4274.835\n",
       "4     2024-03-21 17:00:00+00:00  AAVE  122.06  7042.400"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_cut.copy()\n",
    "df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "if ASSUME_TZ is not None:\n",
    "    df['time'] = df['time'].dt.tz_convert('UTC')\n",
    "\n",
    "assets = sorted({c.split(\"_\")[0] for c in df.columns if c.endswith((\"_price\",\"_volume\"))})\n",
    "\n",
    "# Keep only price/volume pairs that actually exist\n",
    "pairs = []\n",
    "for a in assets:\n",
    "    p, v = f\"{a}_price\", f\"{a}_volume\"\n",
    "    if p in df.columns and v in df.columns:\n",
    "        pairs.append((a, \"price\"))\n",
    "        pairs.append((a, \"volume\"))\n",
    "keep_cols = [\"time\"] + [f\"{a}_price\" for a in assets if f\"{a}_price\" in df.columns] + [f\"{a}_volume\" for a in assets if f\"{a}_volume\" in df.columns]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# Build MultiIndex columns (asset, field)\n",
    "mi_cols = [(\"__meta__\",\"time\")] + [(a,\"price\") for a in assets if f\"{a}_price\" in df.columns] + [(a,\"volume\") for a in assets if f\"{a}_volume\" in df.columns]\n",
    "df.columns = pd.MultiIndex.from_tuples(mi_cols)\n",
    "\n",
    "# To long panel\n",
    "df = df.set_index((\"__meta__\",\"time\"))\n",
    "df.columns.names = [\"asset\",\"field\"]\n",
    "long = df.stack(\"asset\").reset_index().rename(columns={(\"__meta__\",\"time\"): \"time\"})\n",
    "long = long[[\"time\",\"asset\",\"price\",\"volume\"]].sort_values([\"asset\",\"time\"]).reset_index(drop=True)\n",
    "\n",
    "# Hourly reindex & light fill\n",
    "def reindex_hourly(g):\n",
    "    g = g.set_index(\"time\").asfreq(\"1H\")\n",
    "    # Guard against non-positive price before log (set to NaN so it gets dropped later)\n",
    "    g.loc[g[\"price\"] <= 0, \"price\"] = np.nan\n",
    "    g[\"price\"]  = g[\"price\"].ffill()\n",
    "    g[\"volume\"] = g[\"volume\"].fillna(0.0)\n",
    "    return g.reset_index()\n",
    "\n",
    "long = long.groupby(\"asset\", group_keys=False).apply(reindex_hourly)\n",
    "print(\"Long shape after reindex:\", long.shape)\n",
    "long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0375164a",
   "metadata": {},
   "source": [
    "\n",
    "## Feature engineering & label (with NaN cleanup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0888387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 724 rows with NaNs across FEATURES+TARGET\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>field</th>\n",
       "      <th>time</th>\n",
       "      <th>asset</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>log_price</th>\n",
       "      <th>y_ret_h</th>\n",
       "      <th>ret_1h</th>\n",
       "      <th>ret_6h</th>\n",
       "      <th>ret_24h</th>\n",
       "      <th>rv_24h</th>\n",
       "      <th>log_vol</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>price_pct_change</th>\n",
       "      <th>volume_pct_change</th>\n",
       "      <th>target_pct_chage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-22 14:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>115.25</td>\n",
       "      <td>6557.805</td>\n",
       "      <td>4.747104</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>-0.008295</td>\n",
       "      <td>-0.061334</td>\n",
       "      <td>-0.042802</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>8.788564</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.008261</td>\n",
       "      <td>0.920270</td>\n",
       "      <td>-0.059491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-22 15:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>117.76</td>\n",
       "      <td>3082.261</td>\n",
       "      <td>4.768649</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>0.021545</td>\n",
       "      <td>-0.036683</td>\n",
       "      <td>-0.021257</td>\n",
       "      <td>0.015305</td>\n",
       "      <td>8.033743</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>-0.529986</td>\n",
       "      <td>-0.036018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-22 16:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>116.67</td>\n",
       "      <td>1719.785</td>\n",
       "      <td>4.759349</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.009299</td>\n",
       "      <td>-0.021537</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>0.014560</td>\n",
       "      <td>7.450536</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.009256</td>\n",
       "      <td>-0.442038</td>\n",
       "      <td>-0.021307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-22 17:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>117.45</td>\n",
       "      <td>2266.151</td>\n",
       "      <td>4.766013</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>-0.010839</td>\n",
       "      <td>-0.038500</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>7.726279</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.317694</td>\n",
       "      <td>-0.010781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-22 18:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>117.43</td>\n",
       "      <td>893.595</td>\n",
       "      <td>4.765842</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>-0.014793</td>\n",
       "      <td>-0.008649</td>\n",
       "      <td>0.013307</td>\n",
       "      <td>6.796371</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>-0.605677</td>\n",
       "      <td>-0.014684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "field                      time asset   price    volume  log_price   y_ret_h  \\\n",
       "0     2024-03-22 14:00:00+00:00  AAVE  115.25  6557.805   4.747104  0.013188   \n",
       "1     2024-03-22 15:00:00+00:00  AAVE  117.76  3082.261   4.768649 -0.013680   \n",
       "2     2024-03-22 16:00:00+00:00  AAVE  116.67  1719.785   4.759349 -0.000343   \n",
       "3     2024-03-22 17:00:00+00:00  AAVE  117.45  2266.151   4.766013  0.012943   \n",
       "4     2024-03-22 18:00:00+00:00  AAVE  117.43   893.595   4.765842  0.009577   \n",
       "\n",
       "field    ret_1h    ret_6h   ret_24h    rv_24h   log_vol  hour  dow  hour_sin  \\\n",
       "0     -0.008295 -0.061334 -0.042802  0.014545  8.788564    14    4 -0.500000   \n",
       "1      0.021545 -0.036683 -0.021257  0.015305  8.033743    15    4 -0.707107   \n",
       "2     -0.009299 -0.021537 -0.052916  0.014560  7.450536    16    4 -0.866025   \n",
       "3      0.006663 -0.010839 -0.038500  0.014619  7.726279    17    4 -0.965926   \n",
       "4     -0.000170 -0.014793 -0.008649  0.013307  6.796371    18    4 -1.000000   \n",
       "\n",
       "field      hour_cos   dow_sin   dow_cos  price_pct_change  volume_pct_change  \\\n",
       "0     -8.660254e-01 -0.433884 -0.900969         -0.008261           0.920270   \n",
       "1     -7.071068e-01 -0.433884 -0.900969          0.021779          -0.529986   \n",
       "2     -5.000000e-01 -0.433884 -0.900969         -0.009256          -0.442038   \n",
       "3     -2.588190e-01 -0.433884 -0.900969          0.006686           0.317694   \n",
       "4     -1.836970e-16 -0.433884 -0.900969         -0.000170          -0.605677   \n",
       "\n",
       "field  target_pct_chage  \n",
       "0             -0.059491  \n",
       "1             -0.036018  \n",
       "2             -0.021307  \n",
       "3             -0.010781  \n",
       "4             -0.014684  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Log price & label\n",
    "long[\"log_price\"] = np.log(long[\"price\"])\n",
    "long[\"y_ret_h\"] = long.groupby(\"asset\")[\"log_price\"].shift(-HORIZON_H) - long[\"log_price\"]\n",
    "\n",
    "# make sure there are no duplicate (asset, time) rows and the order is stable\n",
    "long = long.sort_values([\"asset\",\"time\"]).drop_duplicates([\"asset\",\"time\"]).reset_index(drop=True)\n",
    "\n",
    "# returns\n",
    "long[\"ret_1h\"]  = long.groupby(\"asset\")[\"log_price\"].diff(1)\n",
    "long[\"ret_6h\"]  = long.groupby(\"asset\")[\"log_price\"].diff(6)\n",
    "long[\"ret_24h\"] = long.groupby(\"asset\")[\"log_price\"].diff(24)\n",
    "\n",
    "# rolling realized volatility over 24 *rows* per asset\n",
    "long[\"rv_24h\"] = (\n",
    "    long.groupby(\"asset\")[\"ret_1h\"]\n",
    "        .transform(lambda s: s.rolling(window=24, min_periods=24).std())\n",
    ")\n",
    "\n",
    "# Volume transform\n",
    "long[\"log_vol\"] = np.log1p(long[\"volume\"])\n",
    "\n",
    "# Calendar\n",
    "long[\"hour\"] = long[\"time\"].dt.hour\n",
    "long[\"dow\"]  = long[\"time\"].dt.dayofweek\n",
    "long[\"hour_sin\"] = np.sin(2*np.pi*long[\"hour\"]/24)\n",
    "long[\"hour_cos\"] = np.cos(2*np.pi*long[\"hour\"]/24)\n",
    "long[\"dow_sin\"]  = np.sin(2*np.pi*long[\"dow\"]/7)\n",
    "long[\"dow_cos\"]  = np.cos(2*np.pi*long[\"dow\"]/7)\n",
    "\n",
    "long[\"price_pct_change\"] = long['price'].pct_change(1)   \n",
    "long[\"volume_pct_change\"] = long['volume'].pct_change(1)\n",
    "long[\"target_pct_chage\"] = long['price'].pct_change(HORIZON_H)\n",
    "\n",
    "# --- Drop rows that cannot be used (NaNs from diffs/rolling/label shift) ---\n",
    "before = len(long)\n",
    "long = long.dropna().reset_index(drop=True)\n",
    "after = len(long)\n",
    "print(f\"Dropped {before-after} rows with NaNs across FEATURES+TARGET\")\n",
    "\n",
    "long.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d280f5d4",
   "metadata": {},
   "source": [
    "\n",
    "## Train / Validation / Test split by time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0160ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes: 176756 37880 37880\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = long[\"time\"].quantile(0.70)\n",
    "t2 = long[\"time\"].quantile(0.85)\n",
    "train = long[long[\"time\"] < t1].copy()\n",
    "val   = long[(long[\"time\"] >= t1) & (long[\"time\"] < t2)].copy()\n",
    "test  = long[long[\"time\"] >= t2].copy()\n",
    "print(\"Split sizes:\", len(train), len(val), len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676bf0b3",
   "metadata": {},
   "source": [
    "\n",
    "## Per-asset scaling on train-only stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "587c98d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>field</th>\n",
       "      <th>time</th>\n",
       "      <th>asset</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>log_price</th>\n",
       "      <th>y_ret_h</th>\n",
       "      <th>ret_1h</th>\n",
       "      <th>ret_6h</th>\n",
       "      <th>ret_24h</th>\n",
       "      <th>rv_24h</th>\n",
       "      <th>log_vol</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>price_pct_change</th>\n",
       "      <th>volume_pct_change</th>\n",
       "      <th>target_pct_chage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-22 14:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>115.25</td>\n",
       "      <td>6557.805</td>\n",
       "      <td>4.747104</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>-0.008295</td>\n",
       "      <td>-0.061334</td>\n",
       "      <td>-0.042802</td>\n",
       "      <td>0.784185</td>\n",
       "      <td>1.366886</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.008261</td>\n",
       "      <td>0.920270</td>\n",
       "      <td>-0.059491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-22 15:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>117.76</td>\n",
       "      <td>3082.261</td>\n",
       "      <td>4.768649</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>0.021545</td>\n",
       "      <td>-0.036683</td>\n",
       "      <td>-0.021257</td>\n",
       "      <td>0.933989</td>\n",
       "      <td>0.675490</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>-0.529986</td>\n",
       "      <td>-0.036018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-22 16:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>116.67</td>\n",
       "      <td>1719.785</td>\n",
       "      <td>4.759349</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.009299</td>\n",
       "      <td>-0.021537</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>0.787231</td>\n",
       "      <td>0.141289</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.009256</td>\n",
       "      <td>-0.442038</td>\n",
       "      <td>-0.021307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-22 17:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>117.45</td>\n",
       "      <td>2266.151</td>\n",
       "      <td>4.766013</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>-0.010839</td>\n",
       "      <td>-0.038500</td>\n",
       "      <td>0.798747</td>\n",
       "      <td>0.393862</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.317694</td>\n",
       "      <td>-0.010781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-22 18:00:00+00:00</td>\n",
       "      <td>AAVE</td>\n",
       "      <td>117.43</td>\n",
       "      <td>893.595</td>\n",
       "      <td>4.765842</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>-0.014793</td>\n",
       "      <td>-0.008649</td>\n",
       "      <td>0.540111</td>\n",
       "      <td>-0.457908</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>-0.605677</td>\n",
       "      <td>-0.014684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "field                      time asset   price    volume  log_price   y_ret_h  \\\n",
       "0     2024-03-22 14:00:00+00:00  AAVE  115.25  6557.805   4.747104  0.013188   \n",
       "1     2024-03-22 15:00:00+00:00  AAVE  117.76  3082.261   4.768649 -0.013680   \n",
       "2     2024-03-22 16:00:00+00:00  AAVE  116.67  1719.785   4.759349 -0.000343   \n",
       "3     2024-03-22 17:00:00+00:00  AAVE  117.45  2266.151   4.766013  0.012943   \n",
       "4     2024-03-22 18:00:00+00:00  AAVE  117.43   893.595   4.765842  0.009577   \n",
       "\n",
       "field    ret_1h    ret_6h   ret_24h    rv_24h   log_vol  hour  dow  hour_sin  \\\n",
       "0     -0.008295 -0.061334 -0.042802  0.784185  1.366886    14    4 -0.500000   \n",
       "1      0.021545 -0.036683 -0.021257  0.933989  0.675490    15    4 -0.707107   \n",
       "2     -0.009299 -0.021537 -0.052916  0.787231  0.141289    16    4 -0.866025   \n",
       "3      0.006663 -0.010839 -0.038500  0.798747  0.393862    17    4 -0.965926   \n",
       "4     -0.000170 -0.014793 -0.008649  0.540111 -0.457908    18    4 -1.000000   \n",
       "\n",
       "field      hour_cos   dow_sin   dow_cos  price_pct_change  volume_pct_change  \\\n",
       "0     -8.660254e-01 -0.433884 -0.900969         -0.008261           0.920270   \n",
       "1     -7.071068e-01 -0.433884 -0.900969          0.021779          -0.529986   \n",
       "2     -5.000000e-01 -0.433884 -0.900969         -0.009256          -0.442038   \n",
       "3     -2.588190e-01 -0.433884 -0.900969          0.006686           0.317694   \n",
       "4     -1.836970e-16 -0.433884 -0.900969         -0.000170          -0.605677   \n",
       "\n",
       "field  target_pct_chage  \n",
       "0             -0.059491  \n",
       "1             -0.036018  \n",
       "2             -0.021307  \n",
       "3             -0.010781  \n",
       "4             -0.014684  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def fit_asset_stats(g):\n",
    "    stats = {}\n",
    "    for col in [\"log_vol\",\"rv_24h\"]:\n",
    "        s = g[col].dropna()\n",
    "        mu = float(s.mean()) if len(s) else 0.0\n",
    "        sd = float(s.std(ddof=0)) if len(s) and s.std(ddof=0) != 0 else 1.0\n",
    "        stats[col] = {\"mean\": mu, \"std\": sd}\n",
    "    return stats\n",
    "\n",
    "asset_stats: Dict[str, Dict[str, Dict[str, float]]] = {a: fit_asset_stats(g) for a, g in train.groupby(\"asset\")}\n",
    "\n",
    "def apply_asset_stats(df_):\n",
    "    out = df_.copy()\n",
    "    for a, g in out.groupby(\"asset\"):\n",
    "        st = asset_stats.get(a, {})\n",
    "        for col in [\"log_vol\",\"rv_24h\"]:\n",
    "            if col in g:\n",
    "                mu = st.get(col, {}).get(\"mean\", 0.0)\n",
    "                sd = st.get(col, {}).get(\"std\", 1.0)\n",
    "                out.loc[g.index, col] = (g[col] - mu) / sd\n",
    "    return out\n",
    "\n",
    "train = apply_asset_stats(train)\n",
    "val   = apply_asset_stats(val)\n",
    "test  = apply_asset_stats(test)\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f40c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c60a67c",
   "metadata": {},
   "source": [
    "\n",
    "## Windowing to sequences & asset embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a594cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assets: 20 {'AAVE': 0, 'ADA': 1, 'AVAX': 2, 'BCH': 3, 'BTC': 4, 'DOGE': 5, 'DOT': 6, 'ETC': 7, 'ETH': 8, 'HBAR': 9, 'LINK': 10, 'LTC': 11, 'SHIB': 12, 'SOL': 13, 'SUI': 14, 'TRX': 15, 'UNI': 16, 'XLM': 17, 'XMR': 18, 'XRP': 19}\n",
      "Sequence shapes: (175796, 48, 1) (36920, 48, 1) (36920, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "asset_to_id = {a:i for i,a in enumerate(sorted(train[\"asset\"].unique()))}\n",
    "n_assets = len(asset_to_id)\n",
    "feat_dim = len(FEATURES)\n",
    "print(\"Assets:\", n_assets, asset_to_id)\n",
    "\n",
    "def make_sequences(df, L):\n",
    "    X_list, A_list, y_list = [], [], []\n",
    "    for a, g in df.groupby(\"asset\"):\n",
    "        g = g.sort_values(\"time\")\n",
    "        X = g[FEATURES].values\n",
    "        A = np.full(len(g), asset_to_id[a], dtype=np.int64)\n",
    "        y = g[TARGET].values\n",
    "        for t in range(L, len(g)):\n",
    "            X_list.append(X[t-L:t,:])\n",
    "            A_list.append(A[t])\n",
    "            y_list.append(y[t])\n",
    "    return np.stack(X_list), np.array(A_list), np.array(y_list)\n",
    "\n",
    "X_tr,A_tr,y_tr = make_sequences(train, LOOKBACK_L)\n",
    "X_va,A_va,y_va = make_sequences(val, LOOKBACK_L)\n",
    "X_te,A_te,y_te = make_sequences(test, LOOKBACK_L)\n",
    "print(\"Sequence shapes:\", X_tr.shape, X_va.shape, X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c0a19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save assets json, to ensure we have the right id later\n",
    "with open(\"paper_wallet_data/asset_to_id.json\", \"w\") as f:\n",
    "    json.dump(asset_to_id, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495939d",
   "metadata": {},
   "source": [
    "\n",
    "## Build `tf.data` datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88ef81c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seq': TensorShape([256, 48, 1]), 'asset_id': TensorShape([256])} -> (256,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_ds(X,A,y,batch=256,shuffle=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(({\"seq\":X,\"asset_id\":A},y))\n",
    "    if shuffle: ds = ds.shuffle(min(len(X),100000), reshuffle_each_iteration=True)\n",
    "    return ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_ds(X_tr,A_tr,y_tr,batch=256,shuffle=True)\n",
    "val_ds   = make_ds(X_va,A_va,y_va,batch=512,shuffle=False)\n",
    "test_ds  = make_ds(X_te,A_te,y_te,batch=512,shuffle=False)\n",
    "for sample in train_ds.take(1):\n",
    "    print({k: v.shape for k,v in sample[0].items()}, \"->\", sample[1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145f4a8",
   "metadata": {},
   "source": [
    "\n",
    "## Model: Asset Embedding + Stacked LSTM (Keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c54e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "\n",
    "returns = Input(shape=(LOOKBACK_L, n_features), name='Returns')\n",
    "tickers = Input(shape=(1,), name='Tickers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4881f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1_units = 25\n",
    "lstm2_units = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ddaca7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "lstm1 = LSTM(units=lstm1_units, \n",
    "             input_shape=(LOOKBACK_L, \n",
    "                          n_features), \n",
    "             name='LSTM1', \n",
    "             dropout=.2,\n",
    "             return_sequences=True)(returns)\n",
    "\n",
    "lstm_model = LSTM(units=lstm2_units, \n",
    "             dropout=.2,\n",
    "             name='LSTM2')(lstm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27e32dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ticker_embedding = Embedding(input_dim=n_assets, \n",
    "                             output_dim=5, \n",
    "                             input_length=1)(tickers)\n",
    "ticker_embedding = Reshape(target_shape=(5,))(ticker_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4f48ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = concatenate([lstm_model, \n",
    "                      ticker_embedding], name='Merged')\n",
    "\n",
    "bn = BatchNormalization()(merged)\n",
    "hidden_dense = Dense(10, name='FC1')(bn)\n",
    "\n",
    "output = Dense(1, name='Output')(hidden_dense)\n",
    "\n",
    "rnn = Model(inputs=[returns, tickers], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0de14ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Returns             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Tickers             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ LSTM1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,700</span> │ Returns[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ Tickers[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ LSTM2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,440</span> │ LSTM1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Merged              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ LSTM2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │ Merged[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ FC1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │ FC1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Returns             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Tickers             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ LSTM1 (\u001b[38;5;33mLSTM\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m25\u001b[0m)    │      \u001b[38;5;34m2,700\u001b[0m │ Returns[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │        \u001b[38;5;34m100\u001b[0m │ Tickers[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ LSTM2 (\u001b[38;5;33mLSTM\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m1,440\u001b[0m │ LSTM1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Merged              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ LSTM2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │         \u001b[38;5;34m60\u001b[0m │ Merged[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ FC1 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m160\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m11\u001b[0m │ FC1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,471</span> (17.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,471\u001b[0m (17.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,441</span> (17.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,441\u001b[0m (17.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02936b99",
   "metadata": {},
   "source": [
    "\n",
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a099e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =tf.keras.optimizers.Adam()\n",
    "\n",
    "rnn.compile(loss='mse',\n",
    "            optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "930a1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('results', 'models')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)\n",
    "    \n",
    "lstm_path = (results_path / 'lstm.regression.keras').as_posix()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=lstm_path,\n",
    "                               verbose=1,\n",
    "                               monitor='val_loss',\n",
    "                               mode='min',\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6157b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience=5,\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "720b4771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175796, 48, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45be326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2746/2747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.4105e-04\n",
      "Epoch 1: val_loss improved from inf to 0.00431, saving model to results/models/lstm.regression.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2747/2747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - loss: 4.4104e-04 - val_loss: 0.0043\n",
      "Epoch 2/50\n",
      "\u001b[1m2744/2747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.4051e-04\n",
      "Epoch 2: val_loss improved from 0.00431 to 0.00097, saving model to results/models/lstm.regression.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2747/2747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - loss: 3.4050e-04 - val_loss: 9.7005e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m 637/2747\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 2.9187e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_tr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_te\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_te\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ✅ both inputs here\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training = rnn.fit([X_tr, A_tr],\n",
    "                   y_tr,\n",
    "                   epochs=50,\n",
    "                   batch_size=64,\n",
    "                    validation_data=([X_te, A_te], y_te),  # ✅ both inputs here\n",
    "                   callbacks=[early_stopping, checkpointer],\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f9b75",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78f0a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 3.894981273333542e-05, 'val_mae': 0.0072752549313008785, 'test_loss': 3.733447374543175e-05, 'test_mae': 0.007075974717736244}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_metrics = model.evaluate(val_ds, verbose=0)\n",
    "test_metrics = model.evaluate(test_ds, verbose=0)\n",
    "print({\"val_loss\": float(val_metrics[0]), \"val_mae\": float(val_metrics[1]),\n",
    "       \"test_loss\": float(test_metrics[0]), \"test_mae\": float(test_metrics[1])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baf390b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to h5 format because mac M1 is silly\n",
    "#model.save(\"models/model.h5\", save_format='h5')\n",
    "#save model to convert to ONNX model later\n",
    "save_model(model=model, filepath=\"models/model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
