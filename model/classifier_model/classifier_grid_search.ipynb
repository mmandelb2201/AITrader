{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Conv1D, MaxPooling1D, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('eth_hourly_data.csv')\n",
    "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "df = df.dropna(subset=['time'])\n",
    "df.sort_values('time', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['high_low_pct'] = (df['high'] - df['low']) / df['open']\n",
    "df['open_close_pct'] = (df['close'] - df['open']) / df['open']\n",
    "df['upper_shadow'] = (df['high'] - df[['open', 'close']].max(axis=1)) / df['open']\n",
    "df['lower_shadow'] = (df[['open', 'close']].min(axis=1) - df['low']) / df['open']\n",
    "df['volume_change'] = df['volume'].pct_change(1)\n",
    "df['volume_rolling_5'] = df['volume'].rolling(5).mean()\n",
    "df['volatility_5'] = df['close'].rolling(5).std()\n",
    "df['atr_5'] = df[['high', 'low', 'close']].apply(lambda row: max(\n",
    "    row['high'] - row['low'],\n",
    "    abs(row['high'] - row['close']),\n",
    "    abs(row['low'] - row['close'])\n",
    "), axis=1).rolling(5).mean()\n",
    "df['volume_price_ratio'] = df['volume'] / df['close']\n",
    "df['zscore_close_5'] = (df['close'] - df['close'].rolling(5).mean()) / df['close'].rolling(5).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = [\n",
    "    'volume_rolling_5', 'upper_shadow', 'lower_shadow', 'volume_change',\n",
    "    'atr_5', 'volatility_5', 'volume_price_ratio', 'zscore_close_5',\n",
    "    'high_low_pct', 'open_close_pct'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_close = df['close'].shift(-3)\n",
    "df['target'] = ((future_close - df['close']) / df['close']).apply(lambda x: 1 if x > 0.0001 else (-1 if x < -0.0001 else 0))\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Data Splitting and Scaling\n",
    "X = df[top_features].values\n",
    "y = df['target'].values\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_labels = y + 1\n",
    "y_cat = to_categorical(y_labels, num_classes=3)\n",
    "\n",
    "# Reshape for LSTM\n",
    "def create_sequences(X, y, window):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(window, len(X)):\n",
    "        X_seq.append(X[i - window:i])\n",
    "        y_seq.append(y[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "window = 10\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_labels, window)\n",
    "y_seq_cat = to_categorical(y_seq, num_classes=3)\n",
    "\n",
    "X_train, X_test = X_seq[:int(0.8*len(X_seq))], X_seq[int(0.8*len(X_seq)):]\n",
    "y_train, y_test = y_seq_cat[:int(0.8*len(y_seq_cat))], y_seq_cat[int(0.8*len(y_seq_cat)):]\n",
    "y_train_labels = y_seq[:int(0.8*len(y_seq))]\n",
    "y_test_labels = y_seq[int(0.8*len(y_seq)):] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "class_weights = dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 4806, 0: 110, 1: 4995}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running config 1/5: {'use_cnn': False, 'lstm_layers': 1, 'units': 64, 'dropout': 0.5}\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Accuracy: 0.5290 | F1 Score: 0.5153\n",
      "\n",
      "Running config 2/5: {'use_cnn': False, 'lstm_layers': 2, 'units': 64, 'dropout': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "Accuracy: 0.5386 | F1 Score: 0.4575\n",
      "\n",
      "Running config 3/5: {'use_cnn': True, 'lstm_layers': 1, 'units': 128, 'dropout': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Accuracy: 0.5225 | F1 Score: 0.5186\n",
      "\n",
      "Running config 4/5: {'use_cnn': True, 'lstm_layers': 2, 'units': 128, 'dropout': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Accuracy: 0.5109 | F1 Score: 0.3455\n",
      "\n",
      "Running config 5/5: {'use_cnn': True, 'lstm_layers': 1, 'units': 128, 'dropout': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Accuracy: 0.5381 | F1 Score: 0.5007\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'use_cnn': [True, False],\n",
    "    'lstm_layers': [1, 2],\n",
    "    'units': [64, 128],\n",
    "    'dropout': [0.0, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "configs = []\n",
    "for _ in range(5):\n",
    "    config = {k: random.choice(v) for k, v in search_space.items()}\n",
    "    configs.append(config)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    print(f\"Running config {i+1}/{len(configs)}: {config}\")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "\n",
    "    if config['use_cnn']:\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    for _ in range(config['lstm_layers']):\n",
    "        model.add(LSTM(config['units'], return_sequences=True))\n",
    "    model.add(LSTM(config['units'], return_sequences=False))\n",
    "\n",
    "    if config['dropout'] > 0:\n",
    "        model.add(Dropout(config['dropout']))\n",
    "\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = classification_report(y_true, y_pred, output_dict=True)['weighted avg']['f1-score']\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f} | F1 Score: {f1:.4f}\\n\")\n",
    "    results.append({\"config\": config, \"accuracy\": acc, \"f1_score\": f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Config: {'use_cnn': True, 'lstm_layers': 1, 'units': 128, 'dropout': 0.5}\n",
      "Best Accuracy: 0.5225, Best F1: 0.5186\n"
     ]
    }
   ],
   "source": [
    "best_result = sorted(results, key=lambda x: x['f1_score'], reverse=True)[0]\n",
    "print(\"Best Config:\", best_result['config'])\n",
    "print(f\"Best Accuracy: {best_result['accuracy']:.4f}, Best F1: {best_result['f1_score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
